{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make selection of months (last month in list won't be requested)\n",
    "\n",
    "months = [] + \\\n",
    "[\"2016-\" + str(month) for month in range(11,13)] + \\\n",
    "[\"2017-0\" + str(month) for month in range(1,10)] + \\\n",
    "[\"2017-\" + str(month) for month in range(10,13)] + \\\n",
    "[\"2018-0\" + str(month) for month in range(1,10)] + \\\n",
    "[\"2018-\" + str(month) for month in range(10,13)] + \\\n",
    "[\"2019-0\" + str(month) for month in range(1,10)] + \\\n",
    "[\"2019-\" + str(month) for month in range(10,11)]\n",
    "\n",
    "# micro choice of months for testing\n",
    "#months = (\"2019-07\", \"2019-08\", \"2019-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topic names from Augmento\n",
    "topics = requests.request(\"Get\", url=\"http://api-dev.augmento.ai/v0.1/topics\")\n",
    "topics = json.loads(topics.content)\n",
    "topics = list(topics.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare request of data from Augmento\n",
    "# bin_size = 24H / 1H\n",
    "\n",
    "def request_and_clean(source, bin_size=\"24H\", coin='bitcoin', months=months):\n",
    "    \n",
    "    url = \"http://api-dev.augmento.ai/v0.1/events/aggregated\"\n",
    "    headers = {}\n",
    "    idx_lastmonth = len(months) - 1\n",
    "    \n",
    "    # initialize dataframe\n",
    "    data_requested = pd.DataFrame()\n",
    "    \n",
    "    #Â loop over months and request data\n",
    "    for idx, month in enumerate(months):\n",
    "        if idx==idx_lastmonth: break\n",
    "\n",
    "        params = {\n",
    "            \"source\" : source,\n",
    "            \"coin\" : coin,\n",
    "            \"bin_size\" : bin_size,\n",
    "            \"count_ptr\" : 1000,\n",
    "            \"start_ptr\" : 0,\n",
    "            \"start_datetime\" : months[idx]+\"-01T00:00:00Z\",\n",
    "            \"end_datetime\" : months[idx+1]+\"-01T00:00:00Z\",\n",
    "        }\n",
    "\n",
    "        r = requests.request(\"GET\", url, params=params, headers=headers)\n",
    "        j = json.loads(r.content)\n",
    "        df = pd.DataFrame(j)\n",
    "        data_requested = data_requested.append(df)\n",
    "        \n",
    "    # unnest topic counts from requested data, change col names\n",
    "    counts = data_requested[\"counts\"].apply(pd.Series)\n",
    "    counts.columns = topics\n",
    "    \n",
    "    # clean data a bit\n",
    "    data_wide = pd.concat((data_requested[\"datetime\"], counts[:]), axis=1)\n",
    "    data_wide.index = pd.to_datetime(data_wide[\"datetime\"], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "    data_wide = data_wide.drop(\"datetime\", axis=1)\n",
    "    \n",
    "    return(data_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request and clean data for bin_size = 24H (default)\n",
    "\n",
    "data_twitter = request_and_clean('twitter')\n",
    "data_reddit = request_and_clean('reddit')\n",
    "data_bitcointalk = request_and_clean('bitcointalk')\n",
    "\n",
    "# sum by position (dataframes are identical)\n",
    "data24h = data_twitter.add(data_reddit)\n",
    "data24h = data24h.add(data_bitcointalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request and clean data for bin_size = 1H (is this required for further steps ???)\n",
    "\n",
    "data_twitter = request_and_clean('twitter', bin_size='1H')\n",
    "data_reddit = request_and_clean('reddit', bin_size='1H')\n",
    "data_bitcointalk = request_and_clean('bitcointalk', bin_size='1H')\n",
    "\n",
    "# sum by position (dataframes are identical)\n",
    "data1h = data_twitter.add(data_reddit)\n",
    "data1h = data1h.add(data_bitcointalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all good:\n",
    "\n",
    "#data_wide\n",
    "\n",
    "#data_wide.describe()\n",
    "#data_wide.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2466 rows in total \n",
      " 0 where price is missing \n",
      " 242 where volume is missing \n",
      " These are all at the end of the dataset, so we can just omit them: \n",
      "\n",
      "2224   2013-12-26\n",
      "2225   2013-12-25\n",
      "2226   2013-12-24\n",
      "2227   2013-12-23\n",
      "2228   2013-12-22\n",
      "          ...    \n",
      "2461   2013-05-03\n",
      "2462   2013-05-02\n",
      "2463   2013-05-01\n",
      "2464   2013-04-30\n",
      "2465   2013-04-29\n",
      "Name: Date, Length: 242, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# prepare volume and price data 24h\n",
    "# source: https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20130429&end=20200129\n",
    "\n",
    "btc = pd.read_csv(\"btc_data.csv\", sep=\";\", thousands=\".\", decimal=\",\")\n",
    "\n",
    "btc.Date = pd.to_datetime(btc[\"Date\"])\n",
    "btc = btc.rename(columns = {\"Close**\":\"BTC_Price\", \"Volume\":\"BTC_Volume\"})\n",
    "btc = btc.drop(columns = [\"Open*\", \"High\", \"Low\", \"Market Cap\"])\n",
    "\n",
    "\n",
    "print(len(btc.axes[0]), \"rows in total\", \"\\n\",\n",
    "sum(btc.BTC_Price == 0), \"where price is missing\", \"\\n\",\n",
    "sum(btc.BTC_Volume == 0), \"where volume is missing\", \"\\n\",\n",
    "\"These are all at the end of the dataset, so we can just omit them: \\n\")\n",
    "print(btc.Date[btc.BTC_Volume == 0])\n",
    "\n",
    "\n",
    "# omit rows w/ missing volume\n",
    "btc = btc[btc.BTC_Volume > 0]\n",
    "\n",
    "# join datasets\n",
    "data24h2 = pd.merge(left=btc, right=data24h, left_on=\"Date\", right_index=True)\n",
    "data24h2 = data24h2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5819 lines excluded as no price available\n"
     ]
    }
   ],
   "source": [
    "# prepare price data 1h\n",
    "# source: http://www.cryptodatadownload.com/cdd/Coinbase_BTCUSD_h.csv\n",
    "# via http://www.cryptodatadownload.com/data/northamerican/ \n",
    "\n",
    "btc_price = pd.read_csv(\"Coinbase_BTCUSD_1h.csv\", skiprows=1)\n",
    "btc_price.index = pd.to_datetime(btc_price[\"Date\"], format='%Y-%m-%d %I-%p')\n",
    "btc_price = btc_price.rename(columns={'Close':'BTC_Price'})\n",
    "\n",
    "\n",
    "# merge topics and prices\n",
    "data1h2 = pd.merge(left=btc_price[[\"BTC_Price\"]], right=data1h, left_index=True, right_index=True)\n",
    "data1h2 = data1h2.reset_index().rename(columns={\"index\":\"datetime\"}) # sort_index()\n",
    "\n",
    "print(len(data1h.axes[0]) - len(data1h2.axes[0]), \"lines excluded as no price available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The created dataset for 24h base has 1064 rows and 96 variables.\n",
      "The created dataset for 1h base has 19717 rows and 95 variables.\n"
     ]
    }
   ],
   "source": [
    "print(\"The created dataset for 24h base has\", len(data24h2.axes[0]), \"rows and\", len(data24h2.axes[1]), \"variables.\")\n",
    "print(\"The created dataset for 1h base has\", len(data1h2.axes[0]), \"rows and\", len(data1h2.axes[1]), \"variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "data1h2.to_csv('../augmento_BTC_1h.csv', index=False)\n",
    "data24h2.to_csv('../augmento_BTC_24h.csv', index=False)\n",
    "data_twitter.to_csv('../augmento_BTC_1h_twitter.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
